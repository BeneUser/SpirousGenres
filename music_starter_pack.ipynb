{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa22828",
   "metadata": {},
   "source": [
    "### REI505M Final project: Music genre classification starter pack\n",
    "\n",
    "The following Dataset class operates on the GTZAN dataset.\n",
    "\n",
    "* The duration of most GTZAN files are 30 seconds (3022050=661500 samples) but some are slightly shorter (approx 29.9 seconds). For this reason we truncate at 660000 samples below.\n",
    "* It may be beneficial to work with smaller chunks than ~30 seconds.\n",
    "* You may want to perform the data augmentations in the `__get_item__` function.\n",
    "* For now, `train_dataset` contains all the dataset, you need to set aside some examples for validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "id": "891d2051",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.Config import Config\n",
    "from src.AudioDataset import AudioDataset\n",
    "from src.DataPreparation import get_partitioned_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d421b32b",
   "metadata": {},
   "source": [
    "config = Config(#Path to folder with GTZAN files:\n",
    "                audio_dir_path='../music/',\n",
    "                # music/\n",
    "                #  - rock/\n",
    "                #       rock.00099.wav\n",
    "                #       ...\n",
    "                #  - reggie/\n",
    "                #  ...\n",
    "                #  - blues/\n",
    "                #Choose how many genres we want to use:\n",
    "                num_genres=2, # eg. 2, 3, 5, 10\n",
    "                #Data Partition\n",
    "                train_part_size=0.7,\n",
    "                val_part_size=0.15,\n",
    "                test_part_size=0.15,\n",
    "                batch_size=32, \n",
    "                learning_rate=1e-3,\n",
    "                epochs=10, \n",
    "                seed=42)\n",
    "\n",
    "torch.manual_seed(config.seed) # Reproducible results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17f6a34a",
   "metadata": {},
   "source": [
    "#Load num_genres from data and partition them\n",
    "train_files, train_labels, val_files, val_labels, test_files, test_labels = get_partitioned_data(config)\n",
    "\n",
    "#Create Datasets and Dataloaders\n",
    "train_dataset = AudioDataset(audio_files=train_files, labels=train_labels,\n",
    "                             audio_path=config.audio_dir_path, \n",
    "                             maxlen=660000, sampling_rate=22050, duration=25)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = AudioDataset(val_files, val_labels, config.audio_dir_path,\n",
    "                           maxlen=660000, sampling_rate=22050, duration=25)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = AudioDataset(test_files, test_labels, config.audio_dir_path,\n",
    "                            maxlen=660000, sampling_rate=22050, duration=25)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)                            \n",
    "\n",
    "\n",
    "tmp_features, tmp_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {tmp_features.size()}\")\n",
    "print(f\"Labels batch shape: {tmp_labels.size()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "496e8be490abbb16",
   "metadata": {},
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, in_c=1, out_c=64, k=7, use_pool=True, n_classes=10):\n",
    "        super().__init__()\n",
    "        pad = k // 2  \n",
    "        self.conv = nn.Conv1d(in_c, out_c, kernel_size=k, stride=2, padding=pad)\n",
    "        self.use_pool = use_pool\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc   = nn.Linear(out_c, n_classes)\n",
    "\n",
    "    def forward(self, x):              \n",
    "        x = nn.functional.relu(self.conv(x))       \n",
    "        x = self.pool(x)           \n",
    "        x = self.gap(x)       \n",
    "        x = x.squeeze(-1)            \n",
    "        logits = self.fc(x)\n",
    "        #probs = F.softmax(logits, dim=-1)\n",
    "        return logits\n",
    "\n",
    "\n",
    "n_classes = config.num_genres \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on:\", device)\n",
    "model = Conv1D(in_c=1, out_c=64, k=7, use_pool=True, n_classes=n_classes).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), config.learning_rate)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "def batch_accuracy(logits, y):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == y).sum().item(), y.size(0)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(config.epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        if xb.dim() == 2:    \n",
    "            xb = xb.unsqueeze(1)\n",
    "        if yb.dtype != torch.long:\n",
    "            yb = yb.long()\n",
    "\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = crit(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        c, t = batch_accuracy(logits, yb)\n",
    "        correct += c\n",
    "        total += t\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"epoch {epoch+1} | train loss {epoch_loss:.4f} | train acc {epoch_acc:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvNet1D(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_c=1,\n",
    "                 out_c=64,           \n",
    "                 k=7,\n",
    "                 use_pool=True,\n",
    "                 n_classes=10,\n",
    "                 num_blocks=3,       # Anzahl Conv-Blocks (r)\n",
    "                 M=256,              # Größe der mittleren FC-Schicht\n",
    "                 channels=None):     \n",
    "        super().__init__()\n",
    "        pad = k // 2\n",
    "\n",
    "   \n",
    "        if channels is None:\n",
    "            channels = []\n",
    "            c = out_c\n",
    "            for _ in range(num_blocks):\n",
    "                channels.append(c)\n",
    "                c = c * 2\n",
    "\n",
    "        layers = []\n",
    "        prev_c = in_c\n",
    "        for c in channels:\n",
    "            # Conv -> ReLU\n",
    "            layers.append(nn.Conv1d(prev_c, c, kernel_size=k, stride=2, padding=pad))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "            # optionaler MaxPool\n",
    "            if use_pool:\n",
    "                layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "\n",
    "            prev_c = c\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(*layers)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)   # (B, C, 1) -> squeeze -> (B, C)\n",
    "\n",
    "        # two FC layers: prev_c -> M -> n_classes\n",
    "        self.fc1 = nn.Linear(prev_c, M)\n",
    "        self.fc2 = nn.Linear(M, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)            # (B, C, L)\n",
    "        x = self.gap(x).squeeze(-1)        # (B, C)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "n_classes = config.num_genres \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on:\", device)\n",
    "\n",
    "model = ConvNet1D(in_c=1, out_c=64, k=7, use_pool=True, n_classes=n_classes, num_blocks=3, M=256).to(device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "def batch_accuracy(logits, y):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == y).sum().item(), y.size(0)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        if xb.dim() == 2:\n",
    "            xb = xb.unsqueeze(1)\n",
    "        if yb.dtype != torch.long:\n",
    "            yb = yb.long()\n",
    "\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = crit(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        c, t = batch_accuracy(logits, yb)\n",
    "        correct += int(c)\n",
    "        total += int(t)\n",
    "\n",
    "    # total ist die Gesamtzahl Samples (gleich len(train_dataset) sofern kein DropLast)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total \n",
    "    print(f\"epoch {epoch+1} | train loss {epoch_loss:.4f} | train acc {epoch_acc:.4f}\")\n"
   ],
   "id": "7b28c1d9fdb4f3f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        if data.dim() == 2:\n",
    "            data = data.unsqueeze(1)\n",
    "        if target.dtype != torch.long:\n",
    "            target = target.long()\n",
    "            \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        logits = model(data)\n",
    "        \n",
    "        batch_loss = crit(logits, target)\n",
    "        batch_size = data.size(0)\n",
    "        \n",
    "        running_loss += batch_loss\n",
    "        \n",
    "        c, t = batch_accuracy(logits, target)\n",
    "        correct += int(c)\n",
    "        total += int(t)\n",
    "        \n",
    "avg_loss = running_loss / total\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"test loss {avg_loss:.4f} | test acc {accuracy:.4f}\")        "
   ],
   "id": "eaec0e3c425d0c09",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spirouvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
