{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa22828",
   "metadata": {},
   "source": [
    "### REI505M Final project: Music genre classification starter pack\n",
    "\n",
    "The following Dataset class operates on the GTZAN dataset.\n",
    "\n",
    "* The duration of most GTZAN files are 30 seconds (3022050=661500 samples) but some are slightly shorter (approx 29.9 seconds). For this reason we truncate at 660000 samples below.\n",
    "* It may be beneficial to work with smaller chunks than ~30 seconds.\n",
    "* You may want to perform the data augmentations in the `__get_item__` function.\n",
    "* For now, `train_dataset` contains all the dataset, you need to set aside some examples for validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891d2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.Conv1D import Conv1D\n",
    "from src.Config import Config\n",
    "from src.AudioDataset import AudioDataset\n",
    "from src.DataPreparation import get_partitioned_data\n",
    "import src.Utils as Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d421b32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d5c2f88830>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training on:\", device)\n",
    "\n",
    "config = Config(#Path to folder with GTZAN files:\n",
    "                audio_dir_path='../music/',\n",
    "                # music/\n",
    "                #  - rock/\n",
    "                #       rock.00099.wav\n",
    "                #       ...\n",
    "                #  - reggie/\n",
    "                #  ...\n",
    "                #  - blues/\n",
    "                #Choose how many genres we want to use:\n",
    "                num_genres=10, # eg. 2, 3, 5, 10\n",
    "                duration_size= 29, # lÃ¤nge der wav-files\n",
    "                sampling_rate = 22050,\n",
    "                #Data Partition\n",
    "                train_part_size=0.7,\n",
    "                val_part_size=0.15,\n",
    "                test_part_size=0.15,\n",
    "                batch_size=8, \n",
    "                learning_rate=1e-3,\n",
    "                epochs=7, \n",
    "                seed=42,\n",
    "                device=device)\n",
    "\n",
    "torch.manual_seed(config.seed) # Reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f6a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 10 genres ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
      "Total selected files 1000 | Training set 700 | Validation set 150 | Test set 150\n",
      "Chosen augmentations [no_augment -> zero]\n",
      "Feature batch shape torch.Size([8, 639450]) | Labels torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "#Load num_genres from data and partition them\n",
    "train_files, train_labels, val_files, val_labels, test_files, test_labels = get_partitioned_data(config)\n",
    "\n",
    "#Create Datasets and Dataloaders\n",
    "train_dataset = AudioDataset(audio_files=train_files, labels=train_labels, audio_path=config.audio_dir_path, \n",
    "                             sampling_rate=config.sampling_rate, \n",
    "                             duration=config.duration_size, #Duration *before* augmentation.\n",
    "                             num_augments=2,\n",
    "                             always_augment=[0, 1],\n",
    "                             print_augments=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = AudioDataset(val_files, val_labels, config.audio_dir_path,\n",
    "                           sampling_rate= config.sampling_rate, duration= config.duration_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = AudioDataset(test_files, test_labels, config.audio_dir_path,\n",
    "                            sampling_rate=config.sampling_rate, duration=config.duration_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)                            \n",
    "\n",
    "\n",
    "tmp_features, tmp_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape {tmp_features.size()} | Labels {tmp_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496e8be490abbb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | train loss 2.3453 | train acc 0.0929 | time 5.14s | per batch 58.44ms\n",
      "epoch 2 | train loss 2.3256 | train acc 0.0900 | time 4.72s | per batch 53.63ms\n",
      "epoch 3 | train loss 2.3279 | train acc 0.0700 | time 4.71s | per batch 53.54ms\n",
      "epoch 4 | train loss 2.3231 | train acc 0.0814 | time 4.69s | per batch 53.34ms\n",
      "epoch 5 | train loss 2.3166 | train acc 0.0771 | time 4.68s | per batch 53.17ms\n",
      "epoch 6 | train loss 2.3193 | train acc 0.0786 | time 4.69s | per batch 53.33ms\n",
      "epoch 7 | train loss 2.3192 | train acc 0.0814 | time 4.68s | per batch 53.13ms\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "n_classes = config.num_genres\n",
    "model = Conv1D(num_blocks=3,\n",
    "               num_conv_layers_per_block=2,\n",
    "               kernel_size=7,\n",
    "               num_first_layer_kernels=32,\n",
    "               conv_stride=2,\n",
    "               pool_stride=2,\n",
    "               dense_size=100,\n",
    "               do_batch_norm=True,\n",
    "               n_classes=n_classes,\n",
    "               config=config\n",
    "               ).to(config.device)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), config.learning_rate)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "Utils.train(train_dataset, train_loader, model, opt, lossfunc=crit, config=config, show_batch_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62009dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 29899.9004 | test acc 0.0800 | time 0.34s | per batch 17.66ms\n"
     ]
    }
   ],
   "source": [
    "#Test model\n",
    "Utils.test(test_dataset, test_loader, model, lossfunc=crit, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spirouvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
