{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa22828",
   "metadata": {},
   "source": [
    "### REI505M Final project: Music genre classification starter pack\n",
    "\n",
    "The following Dataset class operates on the GTZAN dataset.\n",
    "\n",
    "* The duration of most GTZAN files are 30 seconds (3022050=661500 samples) but some are slightly shorter (approx 29.9 seconds). For this reason we truncate at 660000 samples below.\n",
    "* It may be beneficial to work with smaller chunks than ~30 seconds.\n",
    "* You may want to perform the data augmentations in the `__get_item__` function.\n",
    "* For now, `train_dataset` contains all the dataset, you need to set aside some examples for validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891d2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.Config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d421b32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21aebcb78d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(audio_dir_path='../music/', # Path to folder with GTZAN files\n",
    "                # music/\n",
    "                #  - rock/\n",
    "                #       rock.00099.wav\n",
    "                #       ...\n",
    "                #  - reggie/\n",
    "                #  ...\n",
    "                #  - blues/\n",
    "                batch_size=32, \n",
    "                epochs=10, \n",
    "                seed=42)\n",
    "\n",
    "torch.manual_seed(config.seed) # Reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f6a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 genres: ['blues', 'classical']\n",
      "Updated label map: {'blues': 0, 'classical': 1}\n",
      "Total selected files: 200\n",
      "Training set: 140\n",
      "Validation set: 30\n",
      "Test set: 30\n",
      "Feature batch shape: torch.Size([32, 551250])\n",
      "Labels batch shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audio_files, labels, audio_path,\n",
    "                 maxlen, sampling_rate, duration):\n",
    "        self.audio_files = audio_files\n",
    "        self.audio_path = audio_path\n",
    "        self.labels = labels\n",
    "        self.maxlen = maxlen\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.duration = duration\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        audio_file = self.audio_files[idx]\n",
    "        audio_dir = audio_file[:audio_file.index('.')]\n",
    "        file_path = os.path.join(self.audio_path, audio_dir, audio_file)\n",
    "        (rate,audio_samples) = wav.read(file_path)\n",
    "        audio_samples = torch.from_numpy(audio_samples).to(torch.float32)\n",
    "        if len(audio_samples) > self.maxlen:\n",
    "            # Truncate\n",
    "            audio_samples = audio_samples[:self.maxlen]\n",
    "\n",
    "        tstart = 0 # Offset from start of song (hyper-parameter!)\n",
    "        audio_samples = audio_samples[int(self.sampling_rate*tstart):int(self.sampling_rate*(tstart+self.duration))]\n",
    "\n",
    "        return audio_samples, label\n",
    "\n",
    "label_map={'blues' : 0, 'classical' : 1, 'country' : 2,\n",
    "           'disco' : 3, 'hiphop'    : 4, 'jazz'    : 5,\n",
    "           'metal' : 6, 'pop'       : 7, 'reggae'  : 8, 'rock' : 9}\n",
    "\n",
    "\n",
    "\n",
    "# Choose how many genres we want to use\n",
    "num_genres = 2  # <-- change this (2, 3, 5, 10, etc.)\n",
    "\n",
    "# Automatically select the first `num_genres` genres from label_map\n",
    "selected_genres = list(label_map.keys())[:num_genres]\n",
    "\n",
    "# Build a reduced label map only for selected genres\n",
    "label_map = {genre: i for i, genre in enumerate(selected_genres)}\n",
    "\n",
    "print(f\"Using {num_genres} genres: {selected_genres}\")\n",
    "print(\"Updated label map:\", label_map)\n",
    "\n",
    "\n",
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "\"\"\" \n",
    "for root, subdirs, files in os.walk(audio_dir):\n",
    "    for fname in files:\n",
    "        if fname == '.DS_Store':\n",
    "            continue\n",
    "        audio_files.append(fname)\n",
    "        labels.append(label_map[fname[:fname.index('.')]]) \"\"\"\n",
    "\n",
    "# Then make sure your folder traversal loop only collects those folders:\n",
    "for genre in os.listdir(config.audio_dir_path):\n",
    "    if genre not in label_map:\n",
    "        continue\n",
    "    genre_path = os.path.join(config.audio_dir_path, genre)\n",
    "    for fname in os.listdir(genre_path):\n",
    "        if fname.endswith('.wav'):\n",
    "            file_path = os.path.join(genre_path, fname)\n",
    "            audio_files.append(file_path)\n",
    "            labels.append(label_map[genre])\n",
    "\n",
    "print(f\"Total selected files: {len(audio_files)}\")        \n",
    "\n",
    "# ration training - validation - test data\n",
    "# 70% Training, 15% Validation, 15% Test\n",
    "\n",
    "\n",
    "# 70% train, 30% temp\n",
    "train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
    "    audio_files, labels, test_size=0.30, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Split temp 30% -> 15% val + 15% test\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(\n",
    "    temp_files, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train_files)}\")\n",
    "print(f\"Validation set: {len(val_files)}\")\n",
    "print(f\"Test set: {len(test_files)}\")\n",
    "\n",
    "assert len(set(train_files) & set(val_files) & set(test_files)) == 0\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Create validation and test sets\n",
    "#train_files = [audio_files[i] for i in range(len(audio_files))]\n",
    "#train_labels = [labels[i] for i in range(len(audio_files))]\n",
    "#print(\"Training set:\", len(train_files))\n",
    "\n",
    "\n",
    "#print(\"Validation set:\", len(validation_files))\n",
    "\n",
    "\n",
    "#print(\"Test set:\", len(test_files))\n",
    "\n",
    "\n",
    "#assert len(set(train_files) & set(validation_files) & set(test_files)) == 0\n",
    "\n",
    "train_dataset = AudioDataset(audio_files=train_files, labels=train_labels,\n",
    "                             audio_path=config.audio_dir_path, \n",
    "                             maxlen=660000, sampling_rate=22050, duration=25)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "# TODO: Create dataloaders for validation and test sets\n",
    "val_dataset = AudioDataset(val_files, val_labels, config.audio_dir_path,\n",
    "                           maxlen=660000, sampling_rate=22050, duration=25)\n",
    "\n",
    "test_dataset = AudioDataset(test_files, test_labels, config.audio_dir_path,\n",
    "                            maxlen=660000, sampling_rate=22050, duration=25)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)                            \n",
    "\n",
    "\n",
    "tmp_features, tmp_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {tmp_features.size()}\")\n",
    "print(f\"Labels batch shape: {tmp_labels.size()}\")\n",
    "#Test modification for git workflow TESTGITHUB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spirouvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
